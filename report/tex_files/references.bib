
@article{lazaro_approximate_2018,
	title = {Approximate Bayesian inference for mixture cure models},
	url = {http://arxiv.org/abs/1806.09362},
	abstract = {Cure models in survival analysis deal with populations in which a part of the individuals cannot experience the event of interest. Mixture cure models consider the target population as a mixture of susceptible and non-susceptible individuals. The statistical analysis of these models focuses on examining the probability of cure (incidence model) and inferring on the time-to-event in the susceptible subpopulation (latency model). Bayesian inference on mixture cure models has typically relied upon Markov chain Monte Carlo ({MCMC}) methods. The integrated nested Laplace approximation ({INLA}) is a recent and attractive approach for doing Bayesian inference. {INLA} in its natural definition cannot fit mixture models but recent research has new proposals that combine {INLA} and {MCMC} methods to extend its applicability to them (Bivand et al., 2014, G{\textbackslash}'omez-Rubio et al., 2017, G{\textbackslash}'omez-Rubio and Rue, 2018\}. This paper focuses on the implementation of {INLA} in mixture cure models. A general mixture cure survival model with covariate information for the latency and the incidence model within a general scenario with censored and non-censored information is discussed. The fact that non-censored individuals undoubtedly belong to the uncured population is a valuable information that was incorporated in the inferential process.},
	journaltitle = {{arXiv}:1806.09362 [stat]},
	author = {Lázaro, Elena and Armero, Carmen and Gómez-Rubio, Virgilio},
	urldate = {2019-09-26},
	date = {2018-06-25},
	eprinttype = {arxiv},
	eprint = {1806.09362},
	keywords = {Statistics - Computation, Statistics - Methodology},
	file = {arXiv\:1806.09362 PDF:C\:\\Users\\moutz\\Zotero\\storage\\WXHZRNA8\\Lázaro et al. - 2018 - Approximate Bayesian inference for mixture cure mo.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\moutz\\Zotero\\storage\\R43N4TXY\\1806.html:text/html}
}

@article{gomez-rubio_spatial_2017,
	title = {Spatial Models with the Integrated Nested Laplace Approximation within Markov Chain Monte Carlo},
	url = {http://arxiv.org/abs/1702.03891},
	abstract = {The Integrated Nested Laplace Approximation ({INLA}) is a convenient way to obtain approximations to the posterior marginals for parameters in Bayesian hierarchical models when the latent effects can be expressed as a Gaussian Markov Random Field ({GMRF}). In addition, its implementation in the R-{INLA} package for the R statistical software provides an easy way to fit models using {INLA} in practice. R-{INLA} implements a number of widely used latent models, including several spatial models. In addition, R-{INLA} can fit models in a fraction of the time than other computer intensive methods (e.g. Markov Chain Monte Carlo) take to fit the same model. Although {INLA} provides a fast approximation to the marginals of the model parameters, it is difficult to use it with models not implemented in R-{INLA}. It is also difficult to make multivariate posterior inference on the parameters of the model as {INLA} focuses on the posterior marginals and not the joint posterior distribution. In this paper we describe how to use {INLA} within the Metropolis-Hastings algorithm to fit spatial models and estimate the joint posterior distribution of a reduced number of parameters. We will illustrate the benefits of this new method with two examples on spatial econometrics and disease mapping where complex spatial models with several spatial structures need to be fitted.},
	journaltitle = {{arXiv}:1702.03891 [stat]},
	author = {Gómez-Rubio, Virgilio and Palmí-Perales, Francisco},
	date = {2017-02},
	keywords = {Statistics - Computation},
	annotation = {{arXiv}: 1702.03891}
}

@article{gomez-rubio_mixture_2017,
	title = {Mixture model fitting using conditional models and modal Gibbs sampling},
	url = {http://arxiv.org/abs/1712.09566},
	abstract = {In this paper, we present a novel approach to fitting mixture models based on estimating first the posterior distribution of the auxiliary variables that assign each observation to a group in the mixture. The posterior distributions of the remainder of the parameters in the mixture is obtained by averaging over their conditional posterior marginals on the auxiliary variables using Bayesian model averaging. A new algorithm based on Gibbs sampling is used to approximate the posterior distribution of the auxiliary variables without sampling any other parameter in the model. In particular, the modes of the full conditionals of the parameters of the densities in the mixture are computed and these are plugged-in to the full conditional of the auxiliary variables to draw samples. This approximation, that we have called 'modal' Gibbs sampling, reduces the computational burden in the Gibbs sampling algorithm and still provides very good estimates of the posterior distribution of the auxiliary variables. Conditional models on the auxiliary variables are fitted using the Integrated Nested Laplace Approximation ({INLA}) to obtain the conditional posterior distributions, including modes, of the distributional parameters in the mixtures. This approach is general enough to consider mixture models with discrete or continuous outcomes from a wide range of distributions and latent models as conditional model fitting is done with {INLA}. This presents several other advantages, such as fast fitting of the conditional models, not being restricted to the use of conjugate priors on the model parameters and being less prone to label switching. Within this framework, computing the marginal likelihood of the mixture model when the number of groups in the mixture is known is easy and it can be used to tackle selection of the number of components.},
	journaltitle = {{arXiv}:1712.09566 [stat]},
	author = {Gomez-Rubio, Virgilio},
	date = {2017-12},
	keywords = {Statistics - Computation, Statistics - Methodology},
	annotation = {{arXiv}: 1712.09566}
}

@article{gomez-rubio_estimating_2017,
	title = {Estimating Spatial Econometrics Models with Integrated Nested Laplace Approximation},
	url = {http://arxiv.org/abs/1703.01273},
	abstract = {Integrated Nested Laplace Approximation provides a fast and effective method for marginal inference on Bayesian hierarchical models. This methodology has been implemented in the R-{INLA} package which permits {INLA} to be used from within R statistical software. Although {INLA} is implemented as a general methodology, its use in practice is limited to the models implemented in the R-{INLA} package. Spatial autoregressive models are widely used in spatial econometrics but have until now been missing from the R-{INLA} package. In this paper, we describe the implementation and application of a new class of latent models in {INLA} made available through R-{INLA}. This new latent class implements a standard spatial lag model, which is widely used and that can be used to build more complex models in spatial econometrics. The implementation of this latent model in R-{INLA} also means that all the other features of {INLA} can be used for model fitting, model selection and inference in spatial econometrics, as will be shown in this paper. Finally, we will illustrate the use of this new latent model and its applications with two datasets based on Gaussian and binary outcomes.},
	journaltitle = {{arXiv}:1703.01273 [stat]},
	author = {Gomez-Rubio, Virgilio and Bivand, Roger S. and Rue, Håvard},
	date = {2017-03},
	keywords = {Statistics - Computation},
	annotation = {{arXiv}: 1703.01273}
}

@article{gomezrubio_multivariate_2019,
	title = {Multivariate posterior inference for spatial models with the integrated nested Laplace approximation},
	volume = {68},
	issn = {1467-9876},
	url = {https://rss.onlinelibrary.wiley.com/doi/10.1111/rssc.12292},
	doi = {10.1111/rssc.12292},
	abstract = {The integrated nested Laplace approximation ({INLA}) is a convenient way to obtain approximations to the posterior marginals for parameters in Bayesian hierarchical models when the latent effects can b...},
	pages = {199--215},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Gómez‐Rubio, Virgilio and Palmí‐Perales, Francisco},
	urldate = {2019-09-25},
	date = {2019-01-01},
	langid = {english},
	file = {Snapshot:C\:\\Users\\moutz\\Zotero\\storage\\WJ2C5F39\\Gómez‐Rubio and Palmí‐Perales - 2019 - Multivariate posterior inference for spatial model.html:text/html}
}

@article{rue_approximate_2009,
	title = {Approximate Bayesian Inference for Latent Gaussian Models by Using Integrated Nested Laplace Approximations},
	volume = {71},
	issn = {1369-7412},
	url = {https://www.jstor.org/stable/40247579},
	abstract = {Structured additive regression models are perhaps the most commonly used class of models in statistical applications. It includes, among others, (generalized) linear models, (generalized) additive models, smoothing spline models, state space models, semiparametric regression, spatial and spatiotemporal models, log-Gaussian Cox processes and geostatistical and geoadditive models. We consider approximate Bayesian inference in a popular subset of structured additive regression models, latent Gaussian models, where the latent field is Gaussian, controlled by a few hyperparameters and with non-Gaussian response variables. The posterior marginals are not available in closed form owing to the non-Gaussian response variables. For such models, Markov chain Monte Carlo methods can be implemented, but they are not without problems, in terms of both convergence and computational time. In some practical applications, the extent of these problems is such that Markov chain Monte Carlo sampling is simply not an appropriate tool for routine analysis. We show that, by using an integrated nested Laplace approximation and its simplified version, we can directly compute very accurate approximations to the posterior marginals. The main benefit of these approximations is computational: where Markov chain Monte Carlo algorithms need hours or days to run, our approximations provide more precise estimates in seconds or minutes. Another advantage with our approach is its generality, which makes it possible to perform Bayesian analysis in an automatic, streamlined way, and to compute model comparison criteria and various predictive measures so that models can be compared and the model under study can be challenged.},
	pages = {319--392},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	author = {Rue, Håvard and Martino, Sara and Chopin, Nicolas},
	urldate = {2019-09-05},
	date = {2009}
}

@article{hastings_monte_1970,
	title = {Monte Carlo Sampling Methods Using Markov Chains and Their Applications},
	volume = {57},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2334940},
	doi = {10.2307/2334940},
	abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
	pages = {97--109},
	number = {1},
	journaltitle = {Biometrika},
	author = {Hastings, W. K.},
	urldate = {2019-09-05},
	date = {1970},
	file = {JSTOR Full Text PDF:C\:\\Users\\moutz\\Zotero\\storage\\RUC3VPX3\\Hastings - 1970 - Monte Carlo Sampling Methods Using Markov Chains a.pdf:application/pdf}
}

@article{hoeting_bayesian_1999,
	title = {Bayesian Model Averaging: A Tutorial},
	volume = {14},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/2676803},
	shorttitle = {Bayesian Model Averaging},
	abstract = {Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are. Bayesian model averaging ({BMA}) provides a coherent mechanism for accounting for this model uncertainty. Several methods for implementing {BMA} have recently emerged. We discuss these methods and present a number of examples. In these examples, {BMA} provides improved out-of-sample predictive performance. We also provide a catalogue of currently available {BMA} software.},
	pages = {382--401},
	number = {4},
	journaltitle = {Statistical Science},
	author = {Hoeting, Jennifer A. and Madigan, David and Raftery, Adrian E. and Volinsky, Chris T.},
	urldate = {2019-09-05},
	date = {1999}
}

@article{gomez-rubio_markov_2018,
	title = {Markov chain Monte Carlo with the Integrated Nested Laplace Approximation},
	volume = {28},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-017-9778-y},
	doi = {10.1007/s11222-017-9778-y},
	abstract = {The Integrated Nested Laplace Approximation ({INLA}) has established itself as a widely used method for approximate inference on Bayesian hierarchical models which can be represented as a latent Gaussian model ({LGM}). {INLA} is based on producing an accurate approximation to the posterior marginal distributions of the parameters in the model and some other quantities of interest by using repeated approximations to intermediate distributions and integrals that appear in the computation of the posterior marginals. {INLA} focuses on models whose latent effects are a Gaussian Markov random field. For this reason, we have explored alternative ways of expanding the number of possible models that can be fitted using the {INLA} methodology. In this paper, we present a novel approach that combines {INLA} and Markov chain Monte Carlo ({MCMC}). The aim is to consider a wider range of models that can be fitted with {INLA} only when some of the parameters of the model have been fixed. We show how new values of these parameters can be drawn from their posterior by using conditional models fitted with {INLA} and standard {MCMC} algorithms, such as Metropolis–Hastings. Hence, this will extend the use of {INLA} to fit models that can be expressed as a conditional {LGM}. Also, this new approach can be used to build simpler {MCMC} samplers for complex models as it allows sampling only on a limited number of parameters in the model. We will demonstrate how our approach can extend the class of models that could benefit from {INLA}, and how the R-{INLA} package will ease its implementation. We will go through simple examples of this new approach before we discuss more advanced applications with datasets taken from the relevant literature. In particular, {INLA} within {MCMC} will be used to fit models with Laplace priors in a Bayesian Lasso model, imputation of missing covariates in linear models, fitting spatial econometrics models with complex nonlinear terms in the linear predictor and classification of data with mixture models. Furthermore, in some of the examples we could exploit {INLA} within {MCMC} to make joint inference on an ensemble of model parameters.},
	pages = {1033--1051},
	number = {5},
	journaltitle = {Statistics and Computing},
	shortjournal = {Stat Comput},
	author = {Gómez-Rubio, Virgilio and Rue, Håvard},
	urldate = {2019-09-05},
	date = {2018-09-01},
	langid = {english},
	keywords = {Bayesian Lasso, {INLA}, {MCMC}, Missing values, Mixture models, Spatial models},
	file = {Springer Full Text PDF:C\:\\Users\\moutz\\Zotero\\storage\\ZZMBT4IJ\\Gómez-Rubio and Rue - 2018 - Markov chain Monte Carlo with the Integrated Neste.pdf:application/pdf}
}

@article{bivand_approximate_2014,
	title = {Approximate Bayesian inference for spatial econometrics models},
	volume = {9},
	issn = {2211-6753},
	url = {http://www.sciencedirect.com/science/article/pii/S2211675314000037},
	doi = {10.1016/j.spasta.2014.01.002},
	series = {Revealing Intricacies in Spatial and Spatio-Temporal Data: Papers from the Spatial Statistics 2013 Conference},
	abstract = {In this paper we explore the use of the Integrated Laplace Approximation ({INLA}) for Bayesian inference in some widely used models in Spatial Econometrics. Bayesian inference often relies on computationally intensive simulation methods, such as Markov Chain Monte Carlo. When only marginal inference is needed, {INLA} provides a fast and accurate estimate of the posterior marginals of the parameters in the model. Furthermore, we have compared the results provided by these models to those obtained with a more general class of Generalised Linear Models with random effects. In these models, spatial autocorrelation is modelled by means of correlated Gaussian random effects. We also discuss a procedure to extend the class of models that the R-{INLA} software can fit. This approach is based on conditioning on one or more parameters so that the resulting models can be fitted with R-{INLA} across sets of values of the fixed parameters. The posterior marginals of these parameters of interest are then obtained by combining the marginal likelihoods (which are conditioned on the values of the parameters fixed) of the fitted models and a prior on these parameters. This approach can also be used to fit even more general models. Finally, we discuss the use of all these models on two datasets based on median housing prices for census tracts in Boston and the probability of business re-opening in New Orleans in the aftermath of hurricane Katrina.},
	pages = {146--165},
	journaltitle = {Spatial Statistics},
	shortjournal = {Spatial Statistics},
	author = {Bivand, Roger S. and Gómez-Rubio, Virgilio and Rue, Håvard},
	urldate = {2019-09-05},
	date = {2014-08-01},
	keywords = {Bayesian inference, {INLA}, Spatial econometrics},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\moutz\\Zotero\\storage\\7KMW2D89\\Bivand et al. - 2014 - Approximate Bayesian inference for spatial econome.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\moutz\\Zotero\\storage\\AQAQGBVM\\Bivand et al. - 2014 - Approximate Bayesian inference for spatial econome.html:text/html}
}